---
title: "ST558 Project 3 Group F: `r params$label` Summary Report"
author: "Magaritte Nguyen & Matthew Sookoo"
date: "2022-11-12"
output: 
  github_document:
    toc: true
    toc_depth: 6
    df_print: tibble
params: 
  channel: "data_channel_is_lifestyle" 
  label: "Lifestyle"
---

<!-- setup -->
```{r setup, include = FALSE}
#global chunk options
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

#set seed for simulation reproducibility 
set.seed(123)
```

# Introduction 

Our goal with this project is to take the data about articles published by [Mashable](https://www.mashable.com) and create predictive models for the number of shares in social networks (popularity) then automating our Markdown reports. 

This dataset summarizes a heterogeneous set of features in a period of two years. 

Then we will do an Exploratory Data Analysis (EDA) and summarize the data and try to predict the number of shares in two linear regression models, a random forest model, and a boosting model. Lastly we will compare the four models and declare a winner (the model with the lowest root mean squared error (RMSE)).  

The dataset we will be using is [Online News Popularity Data Set](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity).

## More about the variables

The data has 39644 rows of observations and contains 61 variables (58 predictive attributes, 2 non-predictive, 1 goal field) and we are interested in the number of shares (goal) of the online news. 

We only mention the variables we use in our project.

### Response variable 

* "shares" (Number of shares (target))

### Independent or predictor variables

* "data_channel_is_*"    (Lifestyle, Entertainment, Business, Social Media, Tech, World)
   
* "n_tokens_title"       (Number of words in the title),
   
* "n_tokens_content"     (Number of words in the content)
   
* "num_imgs"             (Number of images)
   
* "num_videos"           (Number of videos)
   
* "is_weekend"           (Was the article published on the weekend?)
   
* "num_hrefs"            (Number of links)
 
* "weekday_is_monday"    (Was the article published on a Monday?)

* "weekday_is_tuesday"   (Was the article published on a Tuesday?)

* "weekday_is_wednesday" (Was the article published on a Wednesday?)

* "weekday_is_thursday"  (Was the article published on a Thursday?)

* "weekday_is_friday"    (Was the article published on a Friday?)

* "self_reference_avg_sharess" (Avg. shares of referenced articles in Mashable)




# Required Packages

The following packages are used for our data manipulation, prediction, etc.:

* `tidyverse`: Tons of useful features for data manipulation and visualization!
* `caret`    : Used for predictive modelling.
* `shiny`    : makes it easy to build interactive web apps straight from R
* `rmarkdown`: create dynamic analysis documents that combine codes and rendered output
* `corrplot` : provides a visual exploratory tool on correlation matrix

<!-- packages that we installed and are calling via library() function -->
```{r libraries, include = FALSE}
library(tidyverse)
library(stringr)
library(caret)
library(shiny)
library(rmarkdown)
library(corrplot)
```



# Data

## Reading in the data

Firstly, we set up a relative path and read in the OnlineNewsPopularity.csv data file found [here](https://archive.ics.uci.edu/ml/datasets/Online+News+Popularity) using `read_csv()`. 

For this channel, we will subset the data using the `r params$channel`: Is data channel '`r str_to_title(params$label)`'? variable.

<!-- read in the data  -->
```{r, echo=TRUE, eval=TRUE}
#check working directory
getwd()

#read in data set .csv file in full
#make sure that this is a relative path used
# ./ stays in the same file directory
OnlineNewsPopularity<-read_csv("./OnlineNewsPopularity.csv", show_col_types = FALSE)
#call object OnlineNewsPopularity - our full raw data
OnlineNewsPopularity
```

We now subset the data for the data channel of interest: `r str_to_title(params$label)`.

```{r, echo=TRUE, eval=TRUE}
#subsetting the OnlineNewsPopularity full raw data for the data channel of interest 
Channel <- OnlineNewsPopularity %>% 
               filter(get(params$channel) == 1) %>%
               # removing non-predictive variables per data set description
                select( ! c(url, timedelta ) )

#calling the Channel object to view
Channel
```

Here we can see that after subsetting for the `r str_to_title(params$channel)` variable, that we have `r length(Channel)` observations.



# EDA and Summarizations

Now we split the Channel data set that we've created into a 70% training data set called "ChannelTrain" and a 30% testing data set called "ChannelTest". We will be using the `caret` package with p = 0.7 to achieve the 70% training and 30% testing split.

Note: A seed was set for reproducibility purposes.

<!-- splitting into train and test data  -->
``` {r, echo=TRUE, eval=TRUE}
#seed is set for reproducibility 
set.seed(123)

#indices to split on
ChannelIndex <- createDataPartition(Channel$shares, p = 0.70, list = FALSE)

#subset
ChannelTrain <- Channel[ ChannelIndex, ]
ChannelTest  <- Channel[-ChannelIndex, ]
```

We begin by doing some Exploratory Data Analysis (EDA) below. It should be noted that for the following EDA and summaries are being performed on our training data set -- `ChannelTrain`.

Let's begin by plotting the correlation between a few notable numeric variables.

```{r, echo=TRUE, eval=TRUE}
#performing correlations between variables of interest
cor_mat <- cor(ChannelTrain %>% 
                 select(shares, n_tokens_title, n_tokens_content, num_imgs,
                        num_videos, num_hrefs), method = "pearson")

#correlation plot below
corrplot(cor_mat, 
         hc.order = TRUE,
         type = "lower",
         tl.pos = "lt",
         title = "Correlation Coefficients plot",
         subtitle = "Correlation Coefficients plot",
         mar=c(0,0,2,0)
         )
```

From the above plot, if we do not see large blue or red circles in the plot, then we will note that none of our selected variables appear to share any meaningful correlation.

Next, lets create a few scatter plots to get a better visual of this correlation.

We start by examining the following:

- Trend of Number of words in the content vs. Number of shares  

- Trend of Number of images vs. Number of shares  

- Trend of Number of videos vs. Number of shares   

- Trend of Number of links vs. Number of shares.  

<!-- plot 1 -->
```{r}
ggplot(data = ChannelTrain, aes(y = shares, x = n_tokens_content)) +
       geom_point(aes(color = num_imgs)) +
       geom_smooth(method = "lm") +
       ggtitle("Trend of Number of words in the content vs Number of shares")+
       labs(x = "Number of words in the content" , y = "Number of shares")
```

<!-- plot 2 -->
```{r}
ggplot(data = ChannelTrain, aes(y = shares, x = num_imgs)) +
       geom_point(aes(color = n_tokens_content)) +
       geom_smooth(method = "lm") +
       ggtitle("Trend of Number of images vs Number of shares")+
       labs(x = "Number of images" , y = "Number of shares")
```

<!-- plot 3 -->
```{r}
ggplot(data = ChannelTrain, aes(y = shares, x = num_videos)) +
       geom_point(aes(color = n_tokens_content)) +
       geom_smooth(method = "lm") +
       ggtitle("Trend of Number of videos vs Number of shares")+
       labs(x = "Number of videos" , y = "Number of shares")
```

<!-- plot 4 -->
```{r}
ggplot(data = ChannelTrain, aes(y = shares, x = num_hrefs)) +
       geom_point(aes(color = n_tokens_content)) +
       geom_smooth(method = "lm") +
       ggtitle("Trend of Number of links vs Number of shares")+
       labs(x = "Number of links" , y = "Number of shares")
```

<!-- plot 5 -->
```{r}
ggplot(data = ChannelTrain, aes(y = num_imgs, x = n_tokens_content)) +
       geom_point(aes(color = shares)) +
       geom_smooth(method = "lm") +
       ggtitle("Trend of Number of words in the content vs Number of images")+
       labs(x = "Number of words in the content" , y = "Number of images")
```

From the plots above, if we observe a trend line that is more horizontal and has no noticeable slope, then we can say that there is not a strong correlation between our variables of interest. If there is a noticeable slope in our trend line, then depending on the direction it is pointing, we will have a positive (form left to right, the line slopes upwards) or negative (form left to right, the line slopes downwards) correlation.

Next lets calculate some summary statistics about the `r str_to_title(params$label)` data.

The following tibble shows the mean and standard deviation statistics concerning training data for a number of variables.

```{r}
meanSD1 <- tibble(Variable = c("Number of shares"), 
                  Mean = c(mean(ChannelTrain$shares)), 
                  std_dev = c(sd(ChannelTrain$shares)))

meanSD2 <- tibble(Variable = c("Number of words in the title"), 
                  Mean = c(mean(ChannelTrain$n_tokens_title)), 
                  std_dev = c(sd(ChannelTrain$n_tokens_title)))

meanSD3 <- tibble(Variable = c("Number of words in the content"), 
                  Mean = c(mean(ChannelTrain$n_tokens_content)), 
                  std_dev = c(sd(ChannelTrain$n_tokens_content)))

meanSD4 <- tibble(Variable = c("Number of images"), 
                  Mean = c(mean(ChannelTrain$num_imgs)), 
                  std_dev = c(sd(ChannelTrain$num_imgs)))

meanSD5 <- tibble(Variable = c("Number of videos"), 
                  Mean = c(mean(ChannelTrain$num_videos)), 
                  std_dev = c(sd(ChannelTrain$num_videos)))

#tibble of our summary statistics
rbind(meanSD1, meanSD2, meanSD3, meanSD4, meanSD5)
```

Next, we use the `summary()` function on some more of our variables of interest to get statistics.

```{r, echo=TRUE, eval=TRUE}
#weekday_is_monday: Was the article published on a Monday?
summary(ChannelTrain$weekday_is_monday)
#weekday_is_tuesday: Was the article published on a Tuesday?
summary(ChannelTrain$weekday_is_tuesday)
#weekday_is_wednesday: Was the article published on a Wednesday?
summary(ChannelTrain$weekday_is_wednesday)
#weekday_is_thursday: Was the article published on a Thursday?
summary(ChannelTrain$weekday_is_thursday)
#weekday_is_friday: Was the article published on a Friday?
summary(ChannelTrain$weekday_is_friday)
#weekday_is_saturday: Was the article published on a Saturday?
summary(ChannelTrain$weekday_is_saturday)
#weekday_is_sunday: Was the article published on a Sunday?
summary(ChannelTrain$weekday_is_sunday)
#is_weekend: Was the article published on the weekend? 
summary(ChannelTrain$is_weekend)
#shares: Number of shares (target)
summary(ChannelTrain$shares)
```

Next we create some contingency tables for `r str_to_title(params$label)`.

```{r}
weekend <- table(ChannelTrain$is_weekend)
weekend
```

The above table shows that for our training data, `r weekend[2]` online news articles were published during the weekend and `r weekend[1]` were published during the week.

```{r}
mon_tue <- table(ChannelTrain$weekday_is_monday, ChannelTrain$weekday_is_tuesday)
mon_tue
```

From the above table we see that for our training data, `r mon_tue[2, 1]` online news articles were published on a Monday, `r mon_tue[1, 2]` were published on a Tuesday and `r mon_tue[1, 1]` were published the rest of the week. 

Since Monday is considered the beginning of the work week, it is interesting to see how Monday publications "stack up" in comparison to the other days of the week. For the contingency tables below,  we can use a similar interpretation as we did for the previous table.

```{r}
table(ChannelTrain$weekday_is_monday, ChannelTrain$weekday_is_wednesday)
table(ChannelTrain$weekday_is_monday, ChannelTrain$weekday_is_thursday)
table(ChannelTrain$weekday_is_monday, ChannelTrain$weekday_is_friday)
table(ChannelTrain$weekday_is_monday, ChannelTrain$weekday_is_saturday)
table(ChannelTrain$weekday_is_monday, ChannelTrain$weekday_is_sunday)
```

Next, let us examine the number of publications for the different days of the week using a contingency table and a bar plot.

```{r}
#manipulating/mutating the variables to create one weekday_weekend variable
plot_data_weekday_weekend <- ChannelTrain %>%
                               mutate ( weekday = case_when(
                                          weekday_is_monday    == 1 ~ "Monday"   ,
                                          weekday_is_tuesday   == 1 ~ "Tuesday"  ,
                                          weekday_is_wednesday == 1 ~ "Wednesday",
                                          weekday_is_thursday  == 1 ~ "Thursday" ,
                                          weekday_is_friday    == 1 ~ "Friday"   ,
                                          weekday_is_saturday  == 1 ~ "Saturday" ,
                                          weekday_is_sunday    == 1 ~ "Sunday"   ,
                                          TRUE ~ NA_character_
                                      ),
                                        weekday = factor(
                                          x = weekday,
                                          levels = c("Monday", "Tuesday",
                                                     "Wednesday",
                                                     "Thursday", "Friday",
                                                     "Saturday",
                                                     "Sunday"),
                                          ordered = TRUE
                                          ) )
#contingency table - Monday through Sunday
table(plot_data_weekday_weekend$weekday)

#bar plot 
ggplot(data = plot_data_weekday_weekend, aes(x = weekday)) + 
       geom_bar(aes(fill= weekday)) + 
       ggtitle("Number of Publication During the Week") +
       labs(x="Weekday", y="Shares")
```

The highest value in the contingency table and the highest bar in the bar plot, above, will indicate the day of the week in which the most articles were published and vice versa.

Next we create some scatter plots with box plots overlaid to better visualize the distribution of our data.

Note: Here we had to take the log of the data to better visualize it / it is visually more intuitive with this transformation; otherwise, it would be too small to see anything meaningful.

```{r}
#A scatter plot with boxplots
ggplot(data=plot_data_weekday_weekend, 
            aes(y=shares, x=weekday)) + 
            labs(x="Articles Published on Certain Days of the Week", y="Shares") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday), position="jitter") 
```

This side by side scatter and box plot shows the distribution of the number of shares on the y-axis and the days of the week in which a article was published on the x-axis. We are able to roughly see the minimum, maximum, first and third quadrilles, as well as where the median lies. This will help us spot any outliers or influential points that we can further investigate with other plotting tools.

Next, we break the scatter and box plots down by day and look at whether or not a article was shared on the day they were published or not.

```{r}
#weekday_is_monday: Was the article published on a Monday?
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_monday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Monday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 

#weekday_is_tuesday: Was the article published on a Tuesday
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_tuesday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Tuesday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 

#weekday_is_wednesday: Was the article published on a Wednesday?
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_wednesday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Wednesday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 

#weekday_is_thursday: Was the article published on a Thursday?
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_thursday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Thursday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 

#weekday_is_friday: Was the article published on a Friday?
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_friday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Friday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 

#weekday_is_saturday: Was the article published on a Saturday?
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_saturday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Saturday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 

#weekday_is_sunday: Was the article published on a Sunday?
ggplot(data=ChannelTrain %>% 
            mutate(weekday_fctr = factor(x=weekday_is_sunday,  
            levels=c(0,1), labels = c("No", "Yes"))), 
            aes(y=shares, x=weekday_fctr)) + 
            labs(x="Articles Published on Sunday", y="Shares", 
                 color = "Published") +
            geom_boxplot() + scale_y_log10() +
            geom_point(aes(color=weekday_fctr), position="jitter", alpha=0.4) 
```

We can inspect the trend of shares as a function of the different days of the week that the articles are published. 

If you see a presence of outliers, this may cause the mean to shift in that direction, but the median will not be effected as much. If you see that the median is not centered within the box, then there is a presence of skewness in that particular direction. Also, if you see that there are more observations / dots on one graph while comparing the publication status (Yes/No), this is meaningful within the plot itself and also across the different days of the week.



# Modelling

The data is already split into 70% training and 30% test. Our main goal is to predict the number of shares. This will be our response variable. We will create four models each using 5-fold cross-validation. 

Two models will be multiple linear regression models, one will be a random forest model, and the final model will be a boosted tree model. We will then compare the models and declare a winner based on the model with the lowest (Root Mean Squared Error (RMSE) ) .

We firstly give a brief explanation of a linear regression model.

Linear regression is a supervised learning technique that uses a linear approach for modelling the relationship between a scalar response (dependent variable) and one or more predictor variables (independent variables). 

In the case of one predictor variable, this is called a simple linear regression and in the case where there are more than one predictor variables, this is called multiple linear regression.

Linear regression models are fitted to the data by minimizing the sum of squared residuals.

## First Linear Model

For this first model, we will model the number of shares using multiple linear regression, then summarize, and predict on the testing data called 'ChannelTest'. and use the `postResample()` function to get useful metrics. 

The selected independent variables for this model are:
 
* "n_tokens_title"   (Number of words in the title),

* "n_tokens_content" (Number of words in the content)

* "num_imgs"         (Number of images) : we use the square of this variable

* "num_videos"       (Number of videos) : we use the square of this variable

* "is_weekend"       (Was the article published on the weekend?)

```{r, echo=TRUE, eval=TRUE}
#linear regression model 1
l_m1 <- train(shares ~ n_tokens_title +  n_tokens_content + I(num_imgs^2) +
                       I(num_videos^2) + is_weekend, 
              data = ChannelTrain, 
              method = "lm", 
              preProcess = c("center", "scale"),
              trControl = trainControl(method= "cv", number = 5))
#calling the l_m1 object
l_m1

#summary statistics
summary(l_m1)

#predicting on the ChannelTest data with linear regression model 1
test_pred_l_m1 <- predict(l_m1, newdata = ChannelTest)

#best model chosen - RMSE reported explicitly
#goal is to compare RMSE and see which one is the lowest!
m1 <- postResample(test_pred_l_m1, ChannelTest$shares)
#output object m1
m1
```

## Second Linear Model

For this second model, we will model the number of shares using multiple linear regression, then summarize, and predict on the testing data called 'ChannelTest'. and use the `postResample()` function to get useful metrics. 

The selected independent variables for this model are:

* "num_hrefs"            (Number of links)

* "weekday_is_monday"    (Was the article published on a Monday?)

* "weekday_is_tuesday"   (Was the article published on a Tuesday?)

* "weekday_is_wednesday" (Was the article published on a Wednesday?)

* "weekday_is_thursday"  (Was the article published on a Thursday?)

* "weekday_is_friday"    (Was the article published on a Friday?)

* "self_reference_avg_sharess" (Avg. shares of referenced articles in Mashable)

```{r, echo=TRUE, eval=TRUE}
#linear regression model 2
l_m2 <- train(shares ~ num_hrefs + weekday_is_monday + weekday_is_tuesday +
                       weekday_is_wednesday + weekday_is_thursday +
                       weekday_is_friday + self_reference_avg_sharess,
              data = ChannelTrain, 
              method = "lm", 
              preProcess = c("center", "scale"),
              trControl = trainControl(method= "cv", number = 5))
#calling the l_m2 object
l_m2

#summary statistics
summary(l_m2)

#predictions based on linear model 2 for the ChannelTest data
test_pred_l_m2 <- predict(l_m2, newdata = ChannelTest)

#best model chosen - RMSE reported explicitly
#goal is to compare RMSE and see which one is the lowest!
m2 <- postResample(test_pred_l_m2, ChannelTest$shares)
#calling m2 object
m2
```

## Random Forest Model

The idea behind the random forest model is the same as bagging, but we use a random subset of predictors for each bootstrap sample tree fit (indicated by "mtry"). 

More specifically, it involves:

- creating a boothstrap sample (same size with replacement)
- training the tree on this sample (no pruning necessary)
- repeating the process a large number of times and the final prediction is the average of those predictions

Finding the average of predictions decreases variance, which improves predictions, but unfortunately we lose interpretability.

For our random forest, we model the number of shares by the selected independent variables:
 
* "num_hrefs" (Number of links)

* "n_tokens_content" (Number of words in the content)

* "num_videos" (Number of videos) 

* "is_weekend" (Was the article published on the weekend?)


```{r, echo=TRUE, eval=TRUE}
#Random Forrest Model
r_f <- train(shares ~ num_hrefs +  n_tokens_content + num_videos + 
                      is_weekend, data = ChannelTrain, method = "rf",
             trControl=trainControl(method = "cv", number = 5),
             preProcess = c("center", "scale"),
             tuneGrid = data.frame(mtry = 1:3))
#calling r_f object
r_f

#best model chosen - RMSE reported explicitly
#goal is to compare RMSE and see which one is the lowest!
test_pred_r_f <- predict(r_f, newdata = ChannelTest)
m3 <- postResample(test_pred_r_f, ChannelTest$shares)
#calling m3 object
m3
```

## Boosted Tree Model

The idea behind the boosting tree model is to train our tree slowly in a sequential manner so each tree that is created will be based on the previous one with predictions updated. 

More formally, boosting (for regression trees) involves:

* Initializing predictions

* Finding the residuals

* Fit a tree with (say) d splits (d+1 terminal nodes) treating the residuals as the response

* Update predictions

* Update residuals for new prediction and repeat.

For our boosting tree we model the number of shares by the selected independent variables

* "num_imgs"             (Number of images)

* "weekday_is_monday"    (Was the article published on a Monday?)

* "weekday_is_tuesday"   (Was the article published on a Tuesday?)

* "weekday_is_wednesday" (Was the article published on a Wednesday?)

* "weekday_is_thursday"  (Was the article published on a Thursday?)

* "weekday_is_friday"    (Was the article published on a Friday?)

* "self_reference_avg_sharess" (Avg. shares of referenced articles in Mashable)

Additionally, we choose to use all combinations of the tuning parameters
n.trees = 50, interaction.depth = 1, shrinkage = 0.1 and n.minobsinnode = 10.

```{r, echo=TRUE, eval=TRUE}
#tuning parameters
tune1<- 50
tune2<- 1
tune3<- 0.1
tune4<- 10

#Boosted Tree Model
boosted <- train(shares ~ num_imgs + weekday_is_monday + weekday_is_tuesday +
                          weekday_is_wednesday + weekday_is_thursday +
                          weekday_is_friday + self_reference_avg_sharess, 
           data = ChannelTrain, method = "gbm",
           trControl=trainControl(method = "cv", number = 5),
           preProcess = c("center", "scale"),
           tuneGrid = expand.grid(n.trees = tune1, interaction.depth = tune2,
                                  shrinkage = tune3,    n.minobsinnode = tune4))
#calling boosted object
boosted

#best model chosen - RMSE reported explicitly
#goal is to compare RMSE and see which one is the lowest!
test_pred_boosted <- predict(boosted, newdata = ChannelTest)
m4 <- postResample(test_pred_boosted, ChannelTest$shares)
#calling m4 object
m4
```

Next we do a comparison of the four models



# Comaprison

The `postResample()` function was used to calculate useful statistics such as RMSE and R squared values for each one of the four models. We summarize them in the tibble below.

```{r, echo=TRUE, eval=TRUE}
#creating tibble with RMSE and R-squared values
lm1 <- tibble(model = c("First Linear Regression"), RMSE = c(m1[[1]]), R2 = c(m1[[2]]))

lm2 <- tibble(model = c("Second Linear Regression"), RMSE = c(m2[[1]]), R2 = c(m2[[2]]))

rf <- tibble(model = c("Random Forest"), RMSE = c(m3[[1]]), R2 = c(m3[[2]]))

Bos <- tibble(model = c("Boosting"), RMSE = c(m4[[1]]), R2 = c(m4[[2]]))

#creating tibble for all results for the 4 models
RMSE_table <- rbind(lm1, lm2, rf, Bos)
RMSE_table
```

RMSE is a metric that tells us how far apart the predicted values are from the observed values in a dataset, on average. The lower the RMSE, the better a model fits a dataset.

As for the R2 value we have (R-squared), this is a metric that indicates the proportion of the variance in the response variable of a regression model that can be explained by the predictor variables. The higher the R2 value, the better a model fits a dataset. This value ranges from 0 to 1.

It should be noted that our best model is selected from a model that has results reflecting the lowest RMSE and the highest R2 value. But, there are times when the results from the lowest RMSE and highest R2 are not from the same model; therefore, we will use RMSE to pick our final winner.

```{r, echo=TRUE, eval=TRUE}
#pick the smallest RMSE for the best model
final_result <- RMSE_table %>%
                filter ( min(RMSE) == RMSE )
final_result
```

When comparing all 4 of our models, we are looking for the smallest value of RMSE to tell us which model is the best. In this situation for the `r params$label` channel, we can say that the smallest RMSE value is `r final_result$RMSE` and this value comes from the `r final_result$model` model.
