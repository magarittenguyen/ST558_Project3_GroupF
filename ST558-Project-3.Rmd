---
title: "ST558 Project 3 Group F"
author: "Magaritte Nguyen and Matthew Sookoo"
date: "2022-11-12"
---

<!-- 
############################################################# 
#############################################################
### Project 3 Group F
############################################################# 
############################################################# 
-->

<!-- setup -->
```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

#set seed for simulation reproducibility 
set.seed(123)
```

# Introduction

Our goal with this project is to create predictive models and automating Markdown reports. This dataset summarizes a heterogeneous set of features about articles published by Mashable (www.mashable.com) over a period of two years. We will summarize the data and try to predict the number of shares using linear regression, Random forest and boosting (will add more later)

- briefly describes the data and the variables you have to work with (just discuss the ones you want to use). 
- Your target variables is the shares variable.
- mention the purpose of your analysis and the methods you’ll use to model the response.

- You’ll describe those in more detail later.

Data Set Information:

* The articles were published by Mashable (www.mashable.com) and their content as the rights to reproduce it belongs to them. Hence, this dataset does not share the original content but some statistics associated with it. The original content be publicly accessed and retrieved using the provided urls.

* Acquisition date: January 8, 2015

* The estimated relative performance values were estimated by the authors using a Random Forest classifier and a rolling windows as assessment method. See their article for more details on how the relative performance values were set.


# Required Packages

The following packages are used:

* `tidyverse`: Tons of useful features for data manipulation and visualization!
* `caret`: Used for predictive modelling.

MORE ADDED LATER AS REQUIRED...

<!-- packages that we are calling via library() function -->
```{r libraries, include = FALSE}
library(tidyverse)
library(caret)
```

# Data

Firstly, we read in the data using `read_csv()`
```{r, echo=TRUE, eval=TRUE}
#check working directory
getwd()
#reassign working directory
#Magaritte's directory
#setwd("D:/ST558/Project 3/ST558_Project3_GroupF")
#Matthew's directory
setwd("C:\\Users\\Home Pc\\Desktop\\ST558 Project 3 new\\ST558_Project3_GroupF\\")

#read in data set .csv file in full
#make sure that this is a relative path used...
OnlineNewsPopularity<-read_csv("OnlineNewsPopularity.csv", show_col_types = FALSE)

#call object OnlineNewsPopularity - our full raw data
OnlineNewsPopularity

```

We now subset the data for the channel of interest lifestyle

```{r, echo=TRUE, eval=TRUE}
#subsetting the OnlineNewsPopularity full raw data for the data chennel of interest -- Lifestyle
Lifestyle <- OnlineNewsPopularity %>% 
               filter(data_channel_is_lifestyle == 1)
# %>%  select ( share, var1, var2, var3, ... )
# ! = remove vars -- example below
#select ( ! c(var1, var2, var3, ... ) ) used to remove variables if needed

#calling the Lifestyle object to view
Lifestyle
```


# Summarizations

Now split the data set we’ve created into a training and testing set. Use p = 0.7. 

Here, we are splitting our created data, Lifestyle,  into a training and test set with p=0.7. These datasets will be called `LifestyleTrain` and `LifestyleTest`.

Note: a seed was set for reproduciblility purposes.

``` {r, echo=TRUE, eval=TRUE}
#seed is set for reproducability 
set.seed(123)

#another way to split train and test data below
# #indices to split on
# train <- sample(1:nrow(my_heart), size = nrow(my_heart)*0.70)
# test <- dplyr::setdiff(1:nrow(my_heart), train)
# #subset
# heartTrain <- my_heart[train, ]
# heartTest <- my_heart[test, ]

#indices to split on
LifestyleIndex <- createDataPartition(Lifestyle$shares, p = 0.70, list = FALSE)
#subset
LifestyleTrain <- Lifestyle[ LifestyleIndex, ]
LifestyleTest  <- Lifestyle[-LifestyleIndex, ]

```



```{r, echo=TRUE, eval=TRUE}
#what question are we trying to answer here? 
#response variable is shares, but what does that mean given certain variables available to us?
#maybe look at days of the week variables?
#figure out what kind of object we want to make to answer our question...
#tibble keeping what kind of vars, matrix?

#need to do some sort of type of EDA in order to see if variables are highly correlated
#here we need to summary statistics via summary() and plots

#this shows the summary stats for each variable in our dataset...
Lifestlye_sumstats_Train <- summary(LifestyleTrain)
#calling Lifestlye_sumstats_Train object to see our summary stats
Lifestlye_sumstats_Train
#check structure of objects
str(LifestyleTrain)
str(Lifestlye_sumstats_Train)

#plots include - scatter plots, correlation plots -- plots for continuous data...
#do we need bar plots?

#A scatter plot with the number of shares on the y-axis and the positive word rate on the x-axis is created below
ggplot(data=LifestyleTrain, aes(y=shares, x=rate_positive_words)) + geom_point()

```

# Modelling

The data is already split into 70% training and 30% test. Our main goal is to predict the number of shares. We will create four models each using 5-fold cross-validation.

We begin by creating two multiple linear regression models.

A Linear regression model is a supervised learning technique that is used to predict the value of a variable based on the value of other variable(s). The variable you want to predict is called the dependent variable or the response. The variable(s) you are using to predict is called the independent variable(s) or the predictor(s). 

In both linear models we are using the number of shares as our response variable.

## First linear model.

For the first linear regression model we will model the number of shares by "weekday_is_thursday" (Was the article published on a Thursday?), "weekday_is_friday" (Was the article published on a Friday?) and "is_weekend" (Was the article published on the weekend?). It seems logical to assume that towards the ending of the week (Thursday - Weekend) if an article is published it is more likely to be shared than at the beginning of the week, hence the predictors "weekday_is_thursday", "weekday_is_friday"  and "is_weekend" was chosen for our first linear regression model.


```{r}
l_m1 <- train(shares ~ weekday_is_thursday +  weekday_is_friday + is_weekend, data = LifestyleTrain, method = "lm", 
preProcess = c("center", "scale"),
trControl = trainControl(method= "cv", number = 5))

test_pred_l_m1 <- predict(l_m1, newdata = LifestyleTest)

postResample(test_pred_l_m1, LifestyleTest$shares)
```

## Second linear model

For the second linear regression model we will model the number of shares by "num_imgs" (Number of images), "num_videos" (Number of videos) and "num_hrefs" (Number of links). Pictures and videos in particular can invoke feelings of happiness and as such articles with more pictures and videos are more likely to be shared. Also if there is a greater number of links the greater possibility of the article being viewed and inherently shared. 

For these reasons "num_imgs", "num_videos" and "num_hrefs" were thought to be good predictors for the number of shares.


```{r}
l_m2 <- train(shares ~ num_imgs + num_videos + num_hrefs, data = LifestyleTrain, method = "lm", 
preProcess = c("center", "scale"),
trControl = trainControl(method= "cv", number = 5))

test_pred_l_m2 <- predict(l_m2, newdata = LifestyleTest)

postResample(test_pred_l_m2, LifestyleTest$shares)
```


## Random forest models. used days 
```{r}
r_f <- train(shares ~ weekday_is_thursday +  weekday_is_friday + is_weekend, data = LifestyleTrain, method = "rf",
 trControl=trainControl(method = "cv", number = 5),
 preProcess = c("center", "scale"),
 tuneGrid = data.frame(mtry = 1:15))


test_pred_r_f <- predict(r_f, newdata = LifestyleTest)

postResample(test_pred_r_f, LifestyleTest$shares)

```

## and the boosted tree model Number of images etc


```{r}
tune1<- c(25, 50, 100, 150, 200)
tune2<- 1:4
tune3<- 0.1
tune4<- 10

boosted <- train(shares ~ num_imgs + num_videos + num_hrefs, data = LifestyleTrain, method = "gbm",
 trControl=trainControl(method = "cv", number = 5),
 preProcess = c("center", "scale"),
 tuneGrid = expand.grid(n.trees = tune1, interaction.depth = tune2, shrinkage = tune3,    n.minobsinnode = tune4))

test_pred_boosted <- predict(boosted, newdata = LifestyleTest)

postResample(test_pred_boosted, LifestyleTest$shares)
```

Next we do a comparison of the four models

The model with the lowest rmse is Random Forest-winner



























<!-- # Project Objectives -->
<!-- This is a group project (see the project 3 page for your group member) that involves creating predictive models and automating Markdown reports. Once you’ve completed the project you will also create a blogpost in your blog repo that links to your analyses. -->

# Project Work
The first step is for the first group member to create a github repo and add the second group member as a collaborator. The second group member then needs to accept the membership. This gives everyone access to push changes up to the repository. All project work should be done within this repo.

Each time you go to work on the project, you should pull down any of the latest changes using git pull. You should then upload any changes you’ve made via the usual workflow done previously. There may occasionally be merge conflicts that have to be dealt with. This can be done with the Git tab in RStudio. Let us know if you are having issues with conflicts that you can’t resolve!

# Repo Setting
On your project repo you should go into the settings and enable github pages (feel free to select a theme too!). This will make it so your repo can be accessed like your blog (username.github.io/repo-name). Be sure to choose the master or main branch as the one to use if you have choices there.

You’ll be automating the creation of documents using R Markdown (one for each data_channel_is_* setting, i.e. type of article in the data set provided). Each document should be rendered as a github_document from a single .Rmd file. In the README.md file you should create links to each of the documents you will create (Lifestyle analysis, Entertainment analysis, etc.). Links can be made to the sub-documents using relative
paths. For instance, if you have all of the outputted .md files in the main directory you would just use markdown linking:

- The analysis for [Lifestyle articles is available here](LifestyleAnalysis.html). Note we
link to the html file even though the file we create is a .md file - github creates the .html for us.

In the repo’s README.md file (which doesn’t need to be created from a .Rmd file, just use the one you initialize into the repo if you want) give a brief description of the purpose of the repo, a list of R packages used, links to the generated analyses, and the code used to create the analyses from a single .Rmd file (i.e. the render() code).

# Blog
Once you’ve completed the project each of you should write a brief blog post outlining your project and two links to the username.github.io/repo-name site and the repo itself (the username may correspond to your partner). You should then also reflect on the process you went through. Discuss the following:

- what would you do differently?  
- what was the most difficult part for you?  
- what are your big take-aways from this project?  

# Topic
What are you actually doing? You’ll read in and analyze an online news popularity data set. You’ll subset the data by data_channel_is_* (one of six groups). Then you’ll summarize the data and try to predict the number of shares using predictive models.

1. Read in the OnlineNewsPopularity.csv data file -- subset for data_channel_is_lifestyle: Is data channel 'Lifestyle'?

Here, `read_csv()` is used to read in the OnlineNewsPopularity.csv data and we are subsetting for the `data_channel_is_lifestyle`: Is data channel 'Lifestyle'? variable. 
``` {r, echo=TRUE, eval=TRUE}
#install one time thing
#install.packages("caret")

#read in data set .csv file in full
#OnlineNewsPopularity <- readr::read_csv(file="OnlineNewsPopularity.csv", 
#                                        show_col_types = FALSE)
```


``` {r, echo=TRUE, eval=TRUE}
#subsetting the data for`data_channel_is_lifestyle`: Is data channel 'Lifestyle'?
#Lifestyle <- OnlineNewsPopularity %>% 
#              filter( data_channel_is_lifestyle == 1)

```

# Report
Recommendation: At first, consider just using data from a single data_channel_is_* source. Once you have all of the below steps done for that data, then you can automate it to work with any chosen data channel. Note: It may be easier to create a single variable representing the data channel when automating the subsetting (although there are many ways to do this).  

- All code chunks should be shown unless they are setup code chunks.  

<!-- # Introduction section -->
<!-- You should have an introduction section that briefly describes the data and the variables you have to work with (just discuss the ones you want to use). Your target variables is the shares variable. -->

<!-- You should also mention the purpose of your analysis and the methods you’ll use to model the response. You’ll describe those in more detail later. -->

<!-- **This section should be done by the ‘second’ group member.** -->

<!-- # Data -->
<!-- Use a relative path to import the data. Subset the data to work on the data channel of interest. -->

<!-- **This section should be done by whoever can get to it first.** -->

# Summarizations
You should produce some basic (but meaningful) summary statistics and plots about the training data you are working with (especially as it relates to your response).

As you will automate this same analysis across other data, you can’t describe the trends you see in the graph (unless you want to try to automate that!). You should describe what to look for in the summary statistics/plots to help the reader understand the summary or graph. Ex: A scatter plot with the number of shares on the y-axis and the positive word rate on the x-axis is created:

'We can inspect the trend of shares as a function of the positive word rate. If the points
show an upward trend, then articles with more positive words tend to be shared more often.
If we see a negative trend then articles with more positive words tend to be shared less often.'

Each group member is responsible for producing some summary statistics (means, sds, contingency tables, etc.) and for producing at least three graphs (each) of the data.

# Modeling
You’ll need to split the data into a training (70% of the data) and test set (30% of the data). Use set.seed() to make things reproducible.

The goal is to create models for predicting the number of shares in some way. Each group member should contribute a linear regression model and an ensemble tree-based model. As we are automating things, describing the chosen model is tough, so no need to worry about that.

The first group member should fit a random forest model and the second group member should
fit a boosted tree model. Both models should be chosen using cross-validation.

Prior to the models fit using linear regression, the first group member should provide a short but thorough explanation of the idea of a linear regression model.

Prior to each ensemble model, you should provide a short but reasonably thorough explanation of the ensemble model you are using (so one for each group member).

# Comparison
All four of the models should be compared on the test set and a winner declared (this should be automated to be correct across all the created documents).

This can be done by one group member and the automation done by the other (see below).

# Automation
Once you’ve completed the above for a particular data channel, adapt the code so that you can use a parameter in your build process. You should be able to automatically generate an analysis report for each data_channel_is_* variable - although again, you may want to create a new variable to help with the subsetting. You’ll end up with six total outputted documents.

This should be done by the group member that doesn’t automate the comparison of models
part.

# Submission
In the project submission, you should simply put a link to your blog post (which will have a link to your github pages and github repo).

<!-- # Group Issues -->
<!-- Please notify me ASAP of any group member issues. You should look over your partner’s work/explanations and discuss that with them if you have any issues with what they’ve done. Both group members are graded on all the work done regardless of who was assigned to do it. -->

<!--
Rubric for Grading (total = 100 points)
Item                               Points           Notes
Introduction                       10               Worth either 0, 5, or 10
Data split                          5               Worth either 0 or 5
Summarizations & discussions       20               Worth either 0, 5,. . . , or 20
Modeling, selection, & discussion  35               Worth either 0, 5, . . . , 35
Test set prediction and automation 10               Worth either 0, 5, or 10
Automation                         15               Worth either 0, 5, 10, or 15
Blog post and repo setup           10               Worth either 0, 5, or 10
-->

<!--
Notes on grading:
• For each item in the rubric, your grade will be lowered one level for each each error (syntax, logical, or other) in the code and for each required item that is missing or lacking a description.  
• If your work was not completed and documented using your github repo you will lose 50
points on the project.  
• You should use Good Programming Practices when coding (see wolfware). If you do not follow GPP you can lose up to 40 points on the project.  
• You should use appropriate markdown options/formatting (you can lose up to 20 points) for not doing so.
-->

<!-- code needed to render pdf file  -->

```{r, echo=FALSE, eval=FALSE}
#this code need to be copied and ran in the console to print out results
#otherwise running from within the program doesn't print out every result
#e.g. combo object and the final proportions tibble

rmarkdown:: render("ST558 Project 3.Rmd",
                   output_format = "github_document",
                   output_file = "README.md",
                   output_options = list(html_preview = FALSE, keep_html = FALSE, toc = TRUE, toc_depth = "6", df_print = "tibble"))

#directions
 # - save 
 # - knit file via button
 # - render in the console with code above
 # - click files 3-4 in the Git tab
 # - commit w/ comment button
 # - push .rmd file 
```
